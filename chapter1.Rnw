\chapter{Introduction}
\label{sec:intro}
\chaptermark{Optional running chapter heading}


Different views of the data

\section{Data Settings}
\label{sec:data}


\section{Dissimilarity representation}
 Great progress been made in the theory and applications of pattern recognition, particularly in problem settings where the data available or assumed to be available as vectors in metric spaces. There are still many problems where due to the nature of setting, one only has access to dissimilarities or  proximities or distances between measurements or subjective assessment  of similarities of objects. We thus have a superficial distinction between these two kinds of settings, even though the inference task doesn't distinguish between this representation issue. The gap between the two kinds of representation of data can be bridged using various  techniques, such as different kinds of  embedding.

 \cite{Duin} is a book that compiles the fruits of research in learning from  dissimilarity-based representation. In the introduction, the authors make clear the distinction between statistical and structural(syntactic pattern recognition, which is previously discussed in \cite{NadlerSmith1993} . A common point for the task of discrimination is that both can rely on distances (however they are defined). Pekalska and Duin  suggest dissimilarity measures  are a natural bridge between the two types of information and this is one of the motivating factors for our use of dissimilarity representation in information fusion. 
For feature-based representation, one first defines the features which are either raw or processed measurements from sensors observing the objects and  represention of each object is a single point in the representation space. Dissimilarity-based representation relies on a dissimilarity measure, a way of quantifying the dissimilarity, proximity or similarity between any two objects. It is quite possible the dissimilarity is \emph{designed for} the inference task at hand. There are naturally multiple ways (some more natural than others) of comparing entities and this fact will provide one of the arguments for our approach to information fusion from  data sources, even sources of single modality data. By the latter, it is meant that the same measurements might have different dissimilarity representation according to subjective judgments or different dissimilarity functions. 

\section{Matched Measurements}
Data Fusion is a very general idea and the specific setting of data fusion should be clarified here. The exploitation task we are interested in will involve (perhaps notional) complex objects or abstract entities that are not practically representable. The objects are members of a (perhaps notional) space called "object`` space, $\Xi$ in Figure \ref{gen-model} . We will have different "views``, "measurements`` or "data modalities`` extracted from these objects (which we will refer to as "conditions"), and these observations will be members of the measurement space for those "conditions" ($\Xi_k$ for $k^{th} condition$. Each example of the objects will have an observation in each of the different conditions and the corresponding observations across different "conditions`` will be "matched``. Whether these observations are in dissimilarity representation for each condition, or a dissimilarity can be computed for the observations which are feature observations at each condition is not relevant to our exploitation task: it is assumed one way or another,  dissimilarities for each condition are available for inference purposes       