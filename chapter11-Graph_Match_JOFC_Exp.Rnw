\chapter{The Joint Optimization of Fidelity and Commensurability  solution \\ to Seeded Graph Matching}
\label{sec:sgm-jofc}
\chaptermark{Seeded Graph Matching and JOFC}

\section{Overview}
We first explain the relevance of the JOFC approach to the graph matching problem. The task of finding vertex correspondences is similar to  detecting matched pairs \ref{chap:match_detection} in that both of the tasks require the quantification of a distance between vertex pairs in different graphs. A joint commensurate representation of the vertices of the two graphs  can be used to compute these distances between vertex pairs. A dissimilarity matrix can be computed for each graph using a dissimilarity measure for graph vertices. The choice of the dissimilarity measure is an important issue and we will consider this issue during our investigations. If we treat the known corresponding vertices in the seeded graph matching problem as matched, we can form an omnibus matrix by using dissimilarity matrices from the two graphs. We impute the off-diagonal matrix $L$ in the omnibus matrix the usual way (the matched dissimilarities are zeros, other between-condition dissimilarities are missing).
The joint embedding of the omnibus matrix yields the vertices of two graphs in a commensurate space.
Therefore, the JOFC approach can be used to determine the pairwise distances in the commensurate space between  the vertices of $A$ and $B$.
The next step is to use the pairwise distances as costs to find the optimal one-to-one assignment using the Hungarian algorithm \cite{Hung-algo}. The Hungarian algorithm finds an optimal matching between two sets of vertices such that the total cost, which is the sum of the pairwise distances of matched nodes, is minimized.
%This matching step is separate from the embedding;  we can investigate compare  different parameters for the JOFC approach on a equal footing.
\section{Joint Embedding of Graphs via JOFC for Seeded Graph Matching\label{sec:JOFCforSGM}}
Now, we describe in detail how we use JOFC embedding for seeded graph matching. We begin by jointly embedding our two graphs, $\Graph_1$ and $\Graph_2$, into a common Euclidean space. Let $\Delta_1\in \Mat_{n \times n}$ and $\Delta_2\in \Mat_{n \times n}$ be two dissimilarity matrices computed by the application of the dissimilarity measure to the vertices of the two graphs. Because we have two separate graphs, we have two conditions, and the default assumption is that we do not have between-graph (between-condition) dissimilarities. We will assume that prior to embedding, the dissimilarities have been normalized to have the same scale of magnitude.
%see Remark \ref{rem:norm} for further discussion.

Without loss of generality, we can assume that the vertices in both graphs are labeled as integers  from $1$ to $n$ and that the labeling is consistent with the true correspondence  of vertices from different graphs. Suppose that we have $m,\, 0 \leq m <n$ seeds. Again, without loss of generality, let the seeded vertices be labeled  as the first $m$ vertices in both graphs, $S_1=\{1,2,\ldots,m\}$ and $S_2=\{1,2,\ldots,m\}$, so that 
$$\Delta^{(1)}=\bordermatrix{&S_{1}&U_{in}\cr
                S_1&\gD^{(1)}_{{in},{in}} 
                & \gD^{(1)}_{{in},{oos}}  \cr
                U_1& \gD^{(1)}_{{oos},{in}}  
                &  \gD^{(1)}_{{oos},{oos}}},\,\,
                \Delta^{(2)}=\bordermatrix{&S_2&U_2\cr
                S_2&\gD^{(2)}_{{in},{in}} 
                & \gD^{(2)}_{{in},{oos}}  \cr
                U_2& \gD^{(2)}_{{oos},{in}}  
                &  \gD^{(2)}_{{oos},{oos}}}.$$


Note that the seeds correspond to the in-sample dissimilarities that we considered in the match detection task \ref{chap:match_detection}. Because these seeds provide the known correspondences (matched observations in the match detection task), we embed them using the in-sample JOFC embedding methodology we introduced in \ref{sec:jointembed}. That is, we find a $2m \times d$ configuration matrix  $$\X= \left[\begin{array}{c}
\X_1 \\
\X_2 
\end{array}\right]$$ such that the $2m \times 2m$ distance matrix $\mathcal{D}(\X)$ is as close as possible to the omnibus dissimilarity matrix, $$M= \left[\begin{array}{cc}
\gD^{(1)}_{in,in} & L \\
 L^T &\gD^{(2)}_{in,in}
\end{array} \right] . $$

The remaining non-seed vertices are embedded using OOS embedding with respect to the embedded seeds, i.e., we seek the configuration ${ \hat{\mathbf{Y}}}$ consisting of points in $\mathbb{R}^{d'}$ that consists of the $n-m$ unseeded vertices of $G_1$, with the embedded coordinates  $\{\yhat^{(1)}_{(m+1)},\ldots,\yhat^{(1)}_{(n)}\}$, and the $n-m$ unseeded vertices of $G_2$, with the embedded coordinates  $\{\yhat^{(2)}_1,\ldots,\yhat^{(2)}_{(n-m)}\}$, where $\yhat_{i}^{(k)}, \onespace 1\leq i \leq (n-m), k \in {1,2}$  minimize the stress function:

\begin{align}
\sigma({\bf Y})&=\sum_{s=1}^{m}\sum_{t=m+1}^{n} {W^{(1)}_{in,oos}(s,t-m)  \left(d(X^{(1)}_{s},\yhat_t^{(1)})-\gD^{(1)}_{in,oos}(s,t-m)\right)^2 } \label{eq:oos}\\
&+\sum_{s=m+1}^{n}\sum_{t=1}^{m}
{W^{(2)}_{oos,in}(s-m,t)  \left(d(X^{(2)}_{s},\yhat_t^{(2)})-\gD^{(2)}_{oos,in}(s-m,t)\right)^2}  \label{eq:oos2}\\
&+\sum_{s=m+1}^{n}\sum_{t=1}^{m} 
{W^{(2)}_{oos,oos}(s-m,t-m) \left(d(\yhat_s^{(1)},\yhat_t^{(1)})-\gD^{(1)}_{oos,oos}(s-m,t-m)\right)^2} \label{eq:oos3}\\
&+\sum_{s=m+1}^{n}\sum_{t=1}^{m} 
{W^{(2)}_{oos,oos}(s-m,t-m) \left(d(\yhat_s^{(2)},\yhat_t^{(2)})-\gD^{(2)}_{oos,oos}(s-m,t-m)\right)^2} \label{eq:oos4} \\
&+\sum_{s=m+1}^{n} \sum_{t=1}^{m}
W^{(1,2)}_{oos,oos}(s-m,t-m) \left(d(\yhat_s^{(1)},\yhat_t^{(2)})-\delta(\yhat_s^{(1)},\yhat_t^{(2)})\right)^2 \label{eq:oos5}\\
&+\sum_{s=m+1}^{n} \sum_{t=1}^{m}
W^{(1,2)}_{oos,in}(s-m,t) \left(d(\yhat_s^{(1)},X^{(2)}_{t})-\delta(\yhat_s^{(1)},X^{(2)}_{t})\right)^2 \label{eq:oos6}\\
&+\sum_{s=1}^{m} \sum_{t=m+1}^{n}
W^{(1,2)}_{in,oos}(s,t-m) \left(d(X^{(1)}_{s},\yhat_t^{(2)})-\delta(X^{(1)}_{s},\yhat_t^{(2)})\right)^2 \label{eq:oos7}
%+\sum_{i=1}^{u_1} \sum_{j=1}^{s_2} W^{(1,2)}_{in,oos}(s-m,t) \left(d(Y^{(1)}_i,X^{(2)}_j)-\delta(Y^{(1)}_i,X^{(2)}_j)\right)^2 \\
%&+\sum_{i=1}^{s_1} \sum_{j=1}^{u_2} W^{(1,2)}_{in,oos}(s-m,t-m)\left(d(X^{(1)}_i,Y^{(2)}_j)-\delta(X^{(1)}_i,Y^{(2)}_j)\right)^2, 
\end{align}
%where again $\widetilde w(\cdot,\cdot):V_1\times V_2 \mapsto\mathbb{R}$ are weighting functions representing our confidence in the computed/imputed dissimilarity between pairs of vertices, and as before $\delta$ is the unknown across--graph dissimilarity. 
where $W_{a,b}^{(k)}$ and $W_{a,b}^{(k_1,k_2)}$ (for $a,b \in \{`in', `oos'\}$) are the weights for dissimilarities between in-/out-of-sample observations in $k^{th}$ (or $k_1^{th}$ and $k_2^{th}$) conditions.

Note that \ref{eq:oos5}, \ref{eq:oos6} and \ref{eq:oos7} involve dissimilarities $\delta(.^{(1)},.^{(2)})$ between different conditions, which are generally not available. Whereas  the dissimilarities in \ref{eq:oos6} and \ref{eq:oos7} can be imputed via known dissimilarities, the dissimilarities in \ref{eq:oos5}  cannot be imputed in any way. In fact, if these dissimilarities in  \ref{eq:oos5}   between OOS observations in different conditions were known, we could provide a solution to the assignment task because we would have the assignment cost of any two OOS observations in two different condition. The solution of the linear assignment problem with these costs would give us the matching of vertices from different graphs.

\ref{eq:oos3} and \ref{eq:oos4} contain dissimilarities between OOS observations in the same condition. They can be  used or ignored in the joint embedding, depending on whether one wishes to embed OOS observations all together or one at a time. If between-condition oos dissimilarities are ignored, the OOS embedding function $\sigma({\bf Y})$ is separable with respect to different  $\yhat^{(k)}_{s}, \quad s \in \{ m+1,\ldots n\}$. Then, we would obtain the same embedding configuration if the OOS observations $\yhat^{(k)}_{s},\quad s \in \{m+1,\ldots n\}$ are embedded one at a time.

Once we find a minimum configuration ${ \hat{\mathbf{Y}}}$, we compute the pairwise distances between the points $c_{(s-m)(t-m)}=d(\yhat^{(1)}_s,\yhat^{(2)}_t),\onespace s \in \{(m+1),\ldots n\}, t \in  \{(m+1),\ldots n\}$, which correspond to the entries of the off-diagonal block matrix of the distance matrix, $\mathcal{D}({ \hat{\mathbf{Y}}})$. This block matrix provides the assignment cost matrix $C$ (whose $(i,j)^{th}$   entry is $c_{ij}$) for the linear assignment problem, which is to minimize $\tr(A^{T}C)=\sum_{i,j \in \{(1),\ldots n-m\}} a_{ij}*c_{ij}$  with respect to the permutation matrix $A$ ( whose $(i,j)^{th}$   entry is $a_{ij}$). 

We provide a solution for the seeded graph matching problem by a jointly embedding  the two graphs, followed by a solution of  the linear assignment problem where the distances between embedded points are the assignment costs.
 
One useful property of dissimilarity representation is that the structure of  the data is irrelevant once an appropriate dissimilarity function  for the data is available. 
There are many dissimilarities that can be defined between vertices in graphs. We assume that an appropriate dissimilarity measure between the vertices is available to us.
%See \cite{diffdist}, \cite{dis1}, \cite{dis2} for a wealth of possible dissimilarity measures.  
In our experiments, we will use five different dissimilarities/distances between vertices in a graph:
\begin{itemize}
 \item the shortest path on the  unweighted graph whose adjacency matrix is available
 \item the shortest path on a weighted version of the graph whose weight matrix is available
 \item the diffusion distance between vertices on the (unweighted) graph.
 \item the weighted extension of the Czekanowski-Dice dissimilarity\cite{DICE,weightedDICE}, which simplifies to the original Czekanowski-Dice dissimilarity in the case of unweighted graphs (the C-D dissimilarity quantifies the local similarity of two vertices in a graph).
 \item the expected commute time for random walks on the graph.
 \end{itemize}
 %We will omit the results for weighted graph dissimilarities, since they seem to have the same performance as the weighted dissimilarities.
 \begin{remark}
 Note that these dissimilarities are defined between vertices of the same graph. Because the dissimilarities between vertices of different graphs are not available, we must resort to the same imputation workarounds as we did for the JOFC embedding in  \ref{rem:imputationofdiss}.
 %We impute the inter-condition dissimilarities   as described before in section \ref{omnibus}, or ignore them as defined before in \ref{eq:oos}.
 We would again choose 0 for the dissimilarities between matched vertices and then either impute the remaining unknown dissimilarities or ignore them in the embedding.
 \end{remark}
 
 While it is plausible that the JOFC approach can also be used to solve the seeded graph matching (SGM) problem, it is not obvious that it can compete with the modified FAQ algorithm, which is specifically formulated to solve the  seeded approximate graph matching problem. Why, then, should one choose to use JOFC for SGM?
One of the many problems with the analysis of real data is that the graph representation of real data is 
 not always well-defined and that the correspondence of vertices may be  ambiguous, one-to-many, or many-to-many. 
In such situations, we would prefer a robust algorithm that would still match seeded graphs with satisfactory performance. 
Modified FAQ, in the form that we have presented, cannot handle such pathologies, and significant changes must be made to the modified FAQ algorithm before it can handle them. 


If the true match ratios of the assignments given by the JOFC approach is at least as high as the ones given by the modified FAQ algorithm, we can thus conclude that JOFC is reasonably competitive with the modified FAQ algorithm for seeded graph matching. 

Our simulations using the correlated Erd{\o}s-Renyi graphs and experiments with real graph data are tailored for a comparison of  the two approaches. We compared the algorithms whenever both of the approaches  were  feasible for the problem size (the running times are acceptable). 
 This application of JOFC for seeded graph matching is  investigated  in \cite{SGMviaJOFC} with simulation and real datasets, and some of these results are presented herein.
 

 
 \section{Demonstrations}

We perform SGM simulations with graphs generated according to a paired Erd{\o}s-Renyi graph and experiments on real-life graphs for both the modified FAQ approach and JOFC. The performance measure that we consider is the true match ratio: the number of true matchings of vertices divided by the number of pairs of vertices.

\subsection{Simulations}


  We first present our exploratory simulations to test the JOFC approach and determine the reasonable choices for  the dissimilarity measure and $w$ (Fidelity-Commensurability tradeoff parameter). We will also see how sensitive the results are for different choices of the dissimilarity measure and different $w$ values. 
 
  We consider the same Erd{\o}s-Renyi correlated graphs as in the modified FAQ simulations introduced in \autoref{subsubsec:sgm_sim_results}.
  
  The probability of flipping an entry of the adjacency matrix is the perturbation parameter $p_{pert}$, which is the variable on the x-axis. 
  The performance measure is the proportion of true matches to the number of matches. Note that 
  under chance, the expected number of true matches is 1, as shown with the dashed line. In this particular simulation, we consider the JOFC approach with classical and raw stress variants and compare the performance of each in small graphs. For JOFC with the weighted raw stress function, we set $w=0.8$. The joint embedding with cMDS is compared with the JOFC approach to figure out how the performance measure is sensitive to the Fidelity-Commensurability tradeoff. 
  %$r=20$ and $s=5$. 
  $p_{pert}$ varies from $0$ to $1$ in increments of $0.1$.  
  



  

 
%require(arrayhelpers,quietly=TRUE)

<<JOFC-on-ER-Graph-init, echo=FALSE,fig=FALSE,results='hide',cache=TRUE,trace=TRUE,eval=TRUE,include=FALSE>>=
root.dir<-Sys.getenv("PROJECT_DIR")
setwd(root.dir)
source("./JOFC_MatchDetect/lib/multipleMinimaTest_fn.R")
 #perl <- "C://Program\ Files//MATLAB//R2012a//sys//perl//win32//bin/perl.exe"
require(igraph,quietly=TRUE)
require(optmatch,quietly=TRUE)
require(MASS,quietly=TRUE)
require(clue,quietly=TRUE)
require(MCMCpack,quietly=TRUE)
source("./JOFC_MatchDetect/lib/simulation_math_util_fn.R")
source("./JOFC_MatchDetect/lib/oosMDS.R")
source("./JOFC-GraphMatch/lib/smacofM.R")
source("./JOFC-GraphMatch/lib/oosIM.R")
source("./JOFC-GraphMatch/lib/diffusion_distance.R")
source("./JOFC-GraphMatch/lib/graph_embedding_fn.R")

embed.via.cMDS=TRUE
verbose= FALSE
oos=TRUE
oos.embed.via.cMDS = TRUE
debug.mode= FALSE
a.embed.via.cMDS <-20

n = 50
m = 30 # the first m pairs are known matches ; the last n-m pairs are to-be-matched

div=10

nmc = 100

if(debug.mode){
  div=4
  nmc=5
}

pert=seq(0,1,1.0/div)
npert = length(pert)
diss.meas.list <- c("default","C_dice_weighted","diffusion","ECT","hybrid_DICE_SP","ell1")
num.diss.meas <- length(diss.meas.list)


n.correct.match.jofc.agg = array(0,dim=c(npert,nmc,num.diss.meas))
dimnames(n.correct.match.jofc.agg)[[1]] <- pert
dimnames(n.correct.match.jofc.agg)[[3]] <- diss.meas.list

n.correct.match.jofc = matrix(0,npert,nmc)
nc.jofc.diff = matrix(0,npert,nmc)
nc.jofc.weighted = matrix(0,npert,nmc)
nc.jofc.unweighted = matrix(0,npert,nmc)



nc.cmds = matrix(0,npert,nmc)




#w.vals.vec <- c(0.2,0.5,0.7,0.9)
w.vals.vec<-c(0.8)

w.max.index<-length(w.vals.vec)

matched.cost<-0.01 #If matched.cost is equal to 1, consider an unweighted graph, with edges between matched vertices
#If matched.cost is  between 0 and 1, the graph is weighted with edges between matched vertices with weights equal to matched.cost. Edges between 
# vertices of the same condition have either weight 1 or 2 according to whether they're connected according to given adjacency matrix or not.

d.dim<-8
T.diff<-1
c.imp<- 20

dims.for.dist<-2:d.dim

# these three lines are not really used,  ...
# they just set up a dummy D.M which is the correct object for input to fullmatch".

G<-ER(n,0.5)
G.comb<-omnibusM(G,G,diag(n))
Graph.M <- graph.adjacency(G.comb,weighted= NULL ,mode="undirected")
D.M<-shortest.paths(Graph.M)



seed<-2893479
set.seed(seed)
@

<<JOFC-on-ER-Graph-run, echo=FALSE,fig.show='hide',results='hide',dependson='JOFC-on-ER-Graph-init' ,cache=TRUE,trace=FALSE,eval=TRUE,warning=FALSE>>=
for(imc in 1:nmc)
{
  G<-ER(n,0.5)
	for(ipert in 1:npert)
	{
    
		Y.emb<-NULL
		Gp<-bitflip(G ,pert[ipert],pert[ipert])
    
    oos.sampling<-sample(1:n, size=(n-m), replace=FALSE)
  	in.sample.ind<-rep(TRUE,2*n)
		in.sample.ind[oos.sampling]<-FALSE
		in.sample.ind[n+oos.sampling]<-FALSE
		for ( diss.it in 1:num.diss.meas ){
    diss_measure = diss.meas.list[diss.it]
    print(diss_measure)
     J.1 <- JOFC.graph.custom.dist  (G,Gp,
			in.sample.ind,
			d.dim=d.dim,
			w.vals.vec,
			graph.is.directed  =  FALSE,
			vert_diss_measure  =  diss_measure,
			T.param  =  T.diff,
			num_v_to_embed_at_a_time   =   sum(!in.sample.ind)/2,
			graph.is.weighted=FALSE ,
			sep.err.w=TRUE,   legacy.func= TRUE, const.dim=TRUE)

		#if (imc==1) print(in.sample.ind)
		
		
		M = solveMarriage(J.1[[1]])
		n.correct.match.jofc[ipert,imc] = present(M)         # returns the number correct in the marriage?
    
    n.correct.match.jofc.agg[ipert,imc,diss.it] = n.correct.match.jofc[ipert,imc]/(n-m)
		}
			
     
    #First fill out the entire dissimilarity matrix
    
    Graph.1<-graph.adjacency(G)
		Graph.2<-graph.adjacency(Gp)
		D.1<-shortest.paths(Graph.1)
		D.2<-shortest.paths(Graph.2)
    
		myD.M = D.M
		myD.M[1:n,1:n]=D.1
		myD.M[(n+1):(2*n),(n+1):(2*n)]=D.2
		myD.M[1:n,(n+1):(2*n)]=(D.1+D.2)/2
		myD.M[(n+1):(2*n),1:n]=(D.1+D.2)/2
    
    #Replace the dissimilarity matrix entries which we do not known (in-oos dissimilarities between the graphs)
		for(i in 1:n) for(j in (n+m+1):(2*n))   myD.M[i,j] = myD.M[j,i] = a.embed.via.cMDS
		for(i in (m+1):n) for(j in (n+1):(2*n)) myD.M[i,j] = myD.M[j,i] = a.embed.via.cMDS
		
		
		
			in.sample.vec.for.oos<- c(1:m,(n+1):(n+m))
			in.sample.log.for.oos.embed<- rep(FALSE,2*n)
			in.sample.log.for.oos.embed[in.sample.vec.for.oos]<-TRUE
			myD.M.in<- myD.M[in.sample.log.for.oos.embed, in.sample.log.for.oos.embed]
			ccc = cmdscale(myD.M.in,k=d.dim,eig=T)
			#plot(ccc$eig)
			#pairs(ccc$points , col=colvec,pch=c(Ln,Ln))
			#plot(ccc$points[,c(2,3)] , col=colvec,pch=c(Ln,Ln))
			Y.emb<-oosMDS(myD.M,X=ccc$points, w=ifelse(in.sample.log.for.oos.embed,1,0),init="gower")			 			
			U = as.matrix(dist(Y.emb[,dims.for.dist]))
		
				
		M = solveMarriage(U[1:(n-m),(n-m+1):(2*(n-m))])
		nc.cmds[ipert,imc] = present(M)/(n-m)         # returns the number correct in the marriage?		
	}
}
@


<<JOFC_on_Graphs_Plot,echo=FALSE,eval=TRUE,fig.cap="The matching ratio for seeded graph matching via JOFC is different for different dissimilarity measures. For $n=50$ vertices and $m=30$ seeds, the true matching ratio is plotted against the perturbation parameter $p_{pert}$. Note the U-shape of some of the dissimilarities.",fig.scap="The matching ratio for seeded graph matching via JOFC is different for different dissimilarity measures", dependson='JOFC-on-ER-Graph-init',message=FALSE>>=
require(arrayhelpers,quietly=TRUE)
require(ggplot2,quietly=TRUE)
dimnames(n.correct.match.jofc.agg)[[1]]<- pert
dimnames(n.correct.match.jofc.agg)[[3]] <- c("ShortestPath","WeightedCz-Dice","DiffusionDist","ExpCommuteTime","ShortestPath/Cz-Dice","L_1-Distance")
nc.jofc.lf <- array2df(n.correct.match.jofc.agg,levels=list(pert=TRUE,mc=NULL,diss.meas=TRUE),label.x="nc.ratio")

nc.ratio.mean.sd<-summarySE(data=nc.jofc.lf,measurevar="nc.ratio",groupvars=c("pert","diss.meas"))
ggplot(nc.ratio.mean.sd,aes(x=pert,y=nc.ratio,colour=diss.meas))+geom_errorbar(aes(ymin=nc.ratio-se,ymax=nc.ratio+se),width=.3)+geom_point(aes(group=diss.meas))+geom_line(aes(group=diss.meas))+theme_minimal()+theme(legend.position="bottom")+guides(col = guide_legend(ncol=2))+ylab(expression(paste(delta^(m))))
@


Our first observation from the plot is that for low amounts of perturbation, JOFC performs satisfactorily, that is, most of the test vertices are matched correctly. Various dissimilarity measures can be chosen for the dissimilarity matrix. The appropriate dissimilarity measure might depend on the degree of the distribution and the size of the graph. \autoref{fig:JOFC_on_Graphs_Plot} shows that some dissimilarity measures result in significantly different behavior as $p_{pert}$  changes.

As the perturbation parameter becomes larger, (for all dissimilarity measures) the performance of JOFC degrades until it is indistinguishable from random chance at $p_{pert}=0.5$. For this $p_{pert}$ value, there is no edge correlation between the two graphs because the mutual information between $A_{ij}$ and $B_{ij}$ is 0. At that  $p_{pert}$ value, we expect, on average, the same number of true matches as that obtained by  random chance. Further, this $p_{pert}$ value means that the dissimilarity between truly matched vertices, say with the shortest path distance as the dissimilarity measure, is even larger than you would expect by chance, which means an even smaller number of true matches.


As $p_{pert}$ approaches $1$, $\Graph_2$ approaches the complement of $\Graph_1$. An interesting feature of the plot is the U-shape of the curve for some of the dissimilarities. This invariancy with respect to the complement of the graph should be investigated further.  


<<JOFC_vs_cMDS_on_ER_graph,fig.show='asis',fig.cap="The matching ratio for seeded graph matching via JOFC is compared with classical MDS embedding with OOS extension. For $n=50$ vertices and $m=30$ seeds, the true matching ratio is plotted against the perturbation parameter $p_{pert}$.", fig.scap="The matching ratio for seeded graph matching via JOFC is compared with classical MDS embedding with OOS extension", echo=FALSE,eval=TRUE,dependson='JOFC-on-ER-Graph-init'>>=
require(arrayhelpers,quietly=TRUE)
require(ggplot2,quietly=TRUE)
dimnames(nc.cmds)[[1]]<-pert

nc.cmds.lf<- array2df(nc.cmds,levels=list(pert=TRUE,mc=NULL),label.x="nc.ratio")


nc.cmds.lf<- cbind(nc.cmds.lf,data.frame(diss.meas=rep("ClassicalMDS",nrow(nc.cmds.lf))))
nc.jofc.shortpath.lf <- subset(x=nc.jofc.lf,subset=(nc.jofc.lf$diss.meas=="ShortestPath"))
nc.jofc.shortpath.lf$diss.meas <- "RawStressEmbed"
nc.jofc.vs.cmds.lf <- rbind(nc.jofc.shortpath.lf,nc.cmds.lf)
nc.ratio.mean.sd<-summarySE(data=nc.jofc.vs.cmds.lf ,measurevar="nc.ratio",groupvars=c("pert","diss.meas"))
ggplot(nc.ratio.mean.sd,aes(x=pert,y=nc.ratio,colour=diss.meas))+geom_errorbar(aes(ymin=nc.ratio-se,ymax=nc.ratio+se),width=.3)+geom_point(aes(group=diss.meas))+geom_line(aes(group=diss.meas))+theme_minimal()+theme(legend.position="bottom")+
  #guides(colour=guide_legend(title=NULL))
  scale_colour_discrete(name = "Embedding Method")+
  ylab(expression(paste(delta^(m))))
@ 


















Other than the dissimilarity measure, the embedding methodology could also have a large impact on performance. Our simulations indicate that the performance of the JOFC embedding is significantly better than that of cMDS, as shown in \autoref{fig:JOFC_vs_cMDS_on_ER_graph}. 







%An interesting trend in the graph is that shortest-path based dissimilarities are an improvement over diffusion-path dissimilarities for perturbation parameter less than 0.5 , but as perturbation parameter increases past 0.5, fraction of correct matches for diffusion distance based dissimilarity recovers, while for other dissimilarities the fraction continues to fall. 

%The dissimilarity type that has the best improvement in performance is JOFC with shortest path distances in weighted graphs(unweighted graphs have similar performance).


<<JOFC-on-ER-Graph-w_param-run, echo=FALSE,results='hide',cache=TRUE,trace=TRUE,eval=TRUE,warning=FALSE,dependson='JOFC-on-ER-Graph-init'>>=
diss_measure = "default"

w.vals.vec <- c(0.2,0.5,0.7,0.9,0.95)
  w.max.index <- length(w.vals.vec)

nc.jofc.diff.w       = array(0,dim=c(npert,nmc,length(w.vals.vec)))

nc.jofc.unweighted.w = array(0,dim=c(npert,nmc,length(w.vals.vec)))



# these three lines are not used, really ...
# they just set up a dummy D.M which is the correct object for input to fullmatch".
# i'm just using Sancar's object ... i don't really understand it!
G<-matrix(0,n,n)
G.comb<-matrix(0,2*n,2*n)
Graph.M <- graph.adjacency(G.comb,weighted= NULL ,mode="undirected")
D.M<-shortest.paths(Graph.M)

seed<-123

for(imc in 1:nmc)
{
  G<-ER(n,0.5)
	for(ipert in 1:npert)
	{
		
		Gp<-bitflip(G ,pert[ipert],pert[ipert])
		Graph.1<-graph.adjacency(G)
		Graph.2<-graph.adjacency(Gp)
		D.1<-shortest.paths(Graph.1)
		D.2<-shortest.paths(Graph.2)
		oos.sampling<-sample(1:n,size=n-m,replace=FALSE)
		in.sample.ind<-rep(TRUE,2*n)
		in.sample.ind[oos.sampling]<-FALSE
		in.sample.ind[n+oos.sampling]<-FALSE
		
		
		
      J.3 <- JOFC.graph.custom.dist  (G,Gp,
  		in.sample.ind,
			d.dim=d.dim,
			w.vals.vec,
			graph.is.directed  =  FALSE,
			vert_diss_measure  =  diss_measure,
			T.param  =  T.diff,
			num_v_to_embed_at_a_time   =   sum(!in.sample.ind)/2,
			graph.is.weighted=FALSE ,
			sep.err.w=TRUE,   legacy.func= TRUE, const.dim=TRUE)
		
		for (w.i in 1:w.max.index){
			M = solveMarriage(J.3[[w.i]])
			nc.jofc.unweighted.w[ipert,imc,w.i] = present(M)/(n-m)         # returns the number correct in the marriage?
		}
		
		
		
	}
}
@


<<JOFC-on-ER-Graph-w_param-plot, echo=FALSE,trace=TRUE,eval=TRUE, dependson='JOFC-on-ER-Graph-w_param-run',fig.cap="">>=
require(arrayhelpers,quietly=TRUE)
require(ggplot2,quietly=TRUE)
#print(str(nc.jofc.unweighted.w))
dimnames(nc.jofc.unweighted.w)[[1]] <- pert
dimnames(nc.jofc.unweighted.w)[[3]] <- w.vals.vec

nc.jofc.w.lf<- array2df(nc.jofc.unweighted.w,levels=list(pert=TRUE,mc=NULL,w=TRUE),label.x="nc.ratio")
#print(str(nc.jofc.w.lf))

nc.ratio.mean.sd<-summarySE(data=nc.jofc.w.lf ,measurevar="nc.ratio",groupvars=c("pert","w"))
ggplot(nc.ratio.mean.sd,aes(x=pert,y=nc.ratio,colour=w))+geom_errorbar(aes(ymin=nc.ratio-se,ymax=nc.ratio+se),width=.3)+geom_point(aes(group=w))+geom_line(aes(group=w))+theme_minimal()+theme(legend.position="bottom")+ylab(expression(paste(delta^(m))))

@

The graph in Figure \ref{fig:JOFC-on-ER-Graph-w_param-plot} shows the effect of the weight parameter of stress $w$ on the probability of true matches. 
We note that in this graph matching, for the setting using the shortest path distance as the dissimilarity measure and for the $w$ values we tested, there is no significant difference between the true matching ratios. The choice of the parameter $w$ is thus not necessarily critical for performance in all data settings. 
%\begin{figure}
%\includegraphics{FidCommPaper-graph-plot-4}
%\end{figure}



<<JOFC-on-ER-Graph-d_param-run, echo=FALSE,results='hide',cache=TRUE,trace=TRUE,eval=FALSE,warning=FALSE,dependson='JOFC-on-ER-Graph-init',message=FALSE>>=



seed<-2893479
set.seed(seed)

debug.mode= FALSE
embed.via.cMDS = TRUE
a.embed.via.cMDS <-20

n = 50
m = 30 # the first m pairs are known matches ; the last n-m pairs are to-be-matched

div=10

nmc = 100

if(debug.mode){
  div=4
  nmc=5
}
require(abind,quietly=TRUE)

d.dim.vec<-c(4,6,8,10)
diss_measure = "default"

nc.jofc.diff.d       = array(0,dim=c(npert,nmc,length(d.dim.vec)))
nc.jofc.weighted.d   = array(0,dim=c(npert,nmc,length(d.dim.vec)))
nc.jofc.unweighted.d = array(0,dim=c(npert,nmc,length(d.dim.vec)))

nc.cmds.d           = array(0,dim=c(npert,nmc,length(d.dim.vec)))


G<-ER(n,0.5)
G.comb<-omnibusM(G,G,diag(n))
Graph.M <- graph.adjacency(G.comb,weighted= NULL ,mode="undirected")
D.M<-shortest.paths(Graph.M)

for (d.dim in d.dim.vec){
  dims.for.dist<-2:d.dim
	d.i<-which(d.dim.vec==d.dim)
	for(imc in 1:nmc)
	{
		G<-ER(n,0.5)
		for(ipert in 1:npert)
		{
			
			Gp<-bitflip(G ,pert[ipert],pert[ipert])
			Graph.1<-graph.adjacency(G)
			Graph.2<-graph.adjacency(Gp)
			D.1<-shortest.paths(Graph.1)
			D.2<-shortest.paths(Graph.2)
			oos.sampling<-sample(1:n,size=n-m,replace=FALSE)
			in.sample.ind<-rep(TRUE,2*n)
			in.sample.ind[oos.sampling]<-FALSE
			in.sample.ind[n+oos.sampling]<-FALSE
			
			
			J.3 = JOFC.graph.custom.dist  (G,Gp,
    	in.sample.ind,
			d.dim=d.dim,
			w.vals.vec,
			graph.is.directed  =  FALSE,
			vert_diss_measure  =  diss_measure,
			T.param  =  T.diff,
			num_v_to_embed_at_a_time   =   sum(!in.sample.ind)/2,
			graph.is.weighted=FALSE ,
			sep.err.w=TRUE,   legacy.func= TRUE, const.dim=TRUE)
			
			M = solveMarriage(J.3[[1]])
			nc.jofc.unweighted.d[ipert,imc,d.i] = present(M)         # returns the number correct in the marriage?
			
			
			
			
			
			if (embed.via.cMDS){
				U<-matrix()
				
				myD.M = D.M # i use just the object D.M ... none of the original entries!
				myD.M[1:n,1:n]=D.1
				myD.M[(n+1):(2*n),(n+1):(2*n)]=D.2
				myD.M[1:n,(n+1):(2*n)]=(D.1+D.2)/2
				myD.M[(n+1):(2*n),1:n]=(D.1+D.2)/2
				for(i in 1:n) for(j in (n+m+1):(2*n)) myD.M[i,j] = myD.M[j,i] = a.embed.via.cMDS
				for(i in (m+1):n) for(j in (n+1):(2*n)) myD.M[i,j] = myD.M[j,i] = a.embed.via.cMDS
				
				
				if (oos.embed.via.cMDS){
					
					oos.in.sample.vec<- c(1:m,(n+1):(n+m))
					oos.in.sample.ind<- rep(FALSE,2*n)
					oos.in.sample.ind[oos.in.sample.vec]<-TRUE
					myD.M.in<- myD.M[oos.in.sample.ind,oos.in.sample.ind]
					
					ccc = cmdscale(myD.M.in,k=d.dim,eig=T)
					#plot(ccc$eig)
					#pairs(ccc$points , col=colvec,pch=c(Ln,Ln))
					#plot(ccc$points[,c(2,3)] , col=colvec,pch=c(Ln,Ln))
					Y.emb<-oosMDS(myD.M,X=ccc$points, w=ifelse(oos.in.sample.ind,1,0),init="gower")					
# 			
					U = as.matrix(dist(Y.emb[,dims.for.dist]))
				} else {
					
					
					ccc = cmdscale(myD.M,k=d.dim,eig=T)
					#plot(ccc$eig)
					#pairs(ccc$points , col=colvec,pch=c(Ln,Ln))
					#plot(ccc$points[,c(2,3)] , col=colvec,pch=c(Ln,Ln))
					
					U = as.matrix(dist(ccc$points[ c((m+1):(n),(n+m+1):(n+n)) ,dims.for.dist]))
				}
				M = fullmatch(U[1:(n-m),(n-m+1):(2*(n-m))])
				nc.cmds.d[ipert,imc,d.i] = present(M)         # returns the number correct in the marriage?
			}
			
						
		}
	}
}

nc.jofc.cmds.d<- abind(nc.jofc.unweighted.d ,nc.cmds.d, along = 0.5) #fractional `along` argument creates a new dimension along which the two arrays are combined. it is the first dimension after



@

<<JOFC_on_ER_Graph_d_param-plot, echo=FALSE,trace=TRUE,eval=FALSE,dependson='JOFC-on-ER-Graph-d_param-run',fig.cap="">>=
require(arrayhelpers,quietly=TRUE)
require(ggplot2,quietly=TRUE)




dimnames(nc.jofc.cmds.d)[[1]] <- c("stress","cMDS")
dimnames(nc.jofc.cmds.d)[[2]] <- pert
dimnames(nc.jofc.cmds.d)[[4]] <- d.dim.vec
print(str(nc.jofc.cmds.d))

nc.jofc.d.lf<- array2df(nc.jofc.cmds.d,levels=list(stress.or.cMDS=TRUE,pert=TRUE,mc=NULL,d=TRUE),label.x="nc.ratio")
print(str(nc.jofc.d.lf))

nc.ratio.mean.sd<-summarySE(data=nc.jofc.d.lf ,measurevar="nc.ratio",groupvars=c("pert","d","stress.or.cMDS"))
ggplot(nc.ratio.mean.sd,aes(x=pert,y=nc.ratio,colour=d,shape=stress.or.cMDS))+geom_errorbar(aes(ymin=nc.ratio-se,ymax=nc.ratio+se),width=.3)+geom_point(aes(group=interaction(d,stress.or.cMDS)))+geom_line(aes(group=interaction(d,stress.or.cMDS)))+theme_minimal()+ylab(expression(paste(delta^(m))))

@

%\autoref{fig:JOFC_on_ER_Graph_d_param-plot} shows that the embedding dimension is a more important concern when the classical MDS embedding is used. For JOFC, even the smallest embedding ($d=4$) dimension is large enough so that a significant amount of fidelity  is not  lost, which results in mostly accurate matchings of vertices.




There are a lot  of interesting questions to ponder about the number of known correspondences, such as the following:
\begin{itemize}
\item How many known correspondences are necessary for satisfactory performance for graphs of a given  size?
\item Are there  any ``elbows'' in the curve for the ``match ratio'' vs the number of known correspondences,  after which the cost of more correspondences is not justified by the accompanying increase in ``match ratio''?
\end{itemize}.
We attempt to answer these questions using the Erd{\o}s-Renyi graph pair model that we introduced along with some real-world graphs.

Figure \ref{fig:bitflipJOFC} shows the ``match ratio'' plotted against the number of ``seeds'' for the bitflip simulations (the data are generated using the Erd{\o}s-Renyi graph pair model) using the Czekanowski-Dice dissimilarity measure. 
These results, along with the previous simulations, suggest that even with the perturbation, when a portion of the correspondences are known, it is possible to recover most of the remaining correspondences using JOFC embedding of the pair of graphs. 
We note that the number of correspondences that must be known before the proportion of true matches are satisfactory depends on various factors, such as the size and average connectivity of the graphs, the connectivity of the seed vertices, the dissimilarity measure, and the amount of perturbation between the two graphs. Further investigations into these factors could be fruitful. 
\begin{figure}
\includegraphics[scale=0.75]{bitflip_JOFC}
\caption{Bitflip Simulations for JOFC \label{fig:bitflipJOFC}}
\end{figure}


\subsection{Experiments on real data}

\subsubsection{C. elegans connectome}
 We consider two connectivity graphs of 279 neurons of the nematode \textit{Caenorhabditis elegans} as an example of real-world graph data. The two conditions correspond to the two ways of measuring connectivity among neurons $\Graph_c$ and $\Graph_g$. The connectivity in the first connectome is defined by chemical synapses, a directed connection between two cells. This connectome is represented by a weighted graph, where the weights correspond to the number of synapses identified in images of C. elegans specimens.  The  weight matrix for the first connectivity type is $A_c$, which is not symmetric, has values between 0 and 37, and is relatively sparse (has 2194 nonzero entries). The second connectivity type forms an unweighted graph $\Graph_g$ with the adjacency matrix $A_g$ and is defined by the existence of gap junctions between neurons. $\Graph_g$ is even sparser (1031 nonzero entries) than $\Graph_c$.

We remove isolated vertices from the two graphs and keep the vertices that are connected in both graphs. This leaves $n=253$  vertices. We consider both the original weighted graph for the first connectome and a binarized version of the same graph. We  also consider symmetrized versions of each graph (which leads to directed and undirected graphs, respectively). In the case of weighted graphs, we normalize the two graphs so that they  have approximately the same scale. For the JOFC approach, we use the weighted DICE dissimilarity (which simplifies to the generic DICE dissimilarity in the case of unweighted graphs) to compute $\Delta_c$ and $\Delta_g$.   

\begin{figure}
\includegraphics[scale=0.75]{worm_jofc_vs_faq_wt_unwt-crop}
\caption{Graph Matching experiments on the C. elegans connectomes using JOFC and FAQ algorithms \label{worm_graphmatch}}
\end{figure}

We compare the JOFC approach and the modified FAQ algorithm using the two connectomes. Whereas the true matching ratio ($\delta^{(m)}$) of both approaches is enhanced by the number of seeds,  $\delta^{(m)}$ are relatively low compared with the maximum possible value ($1$). The correlation between the two connectomes is thus small, and we expect that there are biological explanations for this conclusion.  
The first conclusion we can reach from the comparison is that the two approaches are competitive. In fact, the JOFC approach provides significant improvement over the modified FAQ algorithm. The modified FAQ algorithm is not suitable for the situation when one graph is weighted and the other graph is unweighted (as in the weighted case) or the number of nonzero entries are significantly different, as in this case (as in both the weighted or unweighted cases). The JOFC approach works much better in both the weighted and unweighted cases. 

\subsubsection{Enron communication graph}
The Enron communication graph is extracted from the Enron email corpus, which was made public during criminal investigations by the  Federal Energy Regulatory Commission. Though the number of actual users is approximately 150, each email alias is considered a vertex in the communication graph. The original number of email aliases is 184. The whole time interval is divided into 187 subintervals (each corresponding to a week). The emails are grouped according to the time interval of their timestamps. We then construct a time series of graphs $\mathfrak{G}=\{G^{(t)} = (V,E^{(t)})\}$, where $E^{(t)}$ correspond to emails that were sent at the $t^{th}$ interval. We are interested in the intervals $t=130$  and $t=131$ (and $t=132$ for some experiments), as previous  investigations of the corpus found chatter anomalies at these time intervals \cite{EnronStudy}. When isolated vertices (and their corresponding vertices in the other graph) are removed in these two graphs, the number of vertices is reduced to 146. It is these pruned graphs that we match. The first two results are from matching $G(130)$ and $G(131)$. We consider both the undirected and directed versions of the two graphs.


\begin{figure}
\includegraphics[scale=0.75]{enron-JOFC-FAQ-paper.pdf}
\caption{Experiments on the Enron communication graphs for FAQ and JOFC \label{enron_graphmatch_faq_jofc}}
\end{figure}

We compare the performance of the modified-FAQ algorithm with the JOFC algorithm \ref{enron_graphmatch_faq_jofc}. Here, the modified-FAQ algorithm is significantly better than JOFC. This observation  is valid for both directed and undirected versions of the graphs.  With a large  number of seeds, the difference between the two approaches gets smaller. We also note that the performance with the directed graphs is higher than that for the undirected graph for the modified FAQ algorithm, while for the JOFC approach, the  results are  better with  the undirected graph.

\begin{figure}
\includegraphics[scale=0.75]{JOFC-enron_dim_20}
\caption{Experiments on the Enron communication graphs for JOFC \label{enron_graphmatch}}
\end{figure}

For the plot in  $\ref{enron_graphmatch}$, we chose the embedding dimension $d$ to be 20. These results are better compared with those in \autoref{enron_graphmatch_faq_jofc}, which leads us to conclude that $d$ is another parameter that must be chosen with care. 


\begin{figure}
\includegraphics[scale=0.75]{enron-paper.pdf}
\caption{Experiments on the Enron communication graphs for FAQ for t=130, 131, and 132 \label{enron_graphmatch_faq_t}}
\end{figure}
The plot in \autoref{enron_graphmatch_faq_t} is another result obtained from matching the Enron graphs using the FAQ algorithm, showing a comparison of the three pairs from $t=130, 131, \textrm{ and } 132$. 
As one would expect, the graph matching between $G(130)$ and $G(131)$ is much more successful than is the graph matching between $G(130)$ and $G(132)$. We also note that if enough seeds are available, even the matching between  $G(130)$ and $G(132)$ can be improved significantly. In fact, the improvement in the graph matching between  $G(130)$ and $G(132)$  is larger than that obtained for the graph matching of the other two pairs.

We are also interested in the chatter anomaly detected in \cite{EnronStudy}. This anomaly is detected at $t=132$. We also see from the graph matching results that the matching between $t=130$ and $131$ is better than the matching between $G(131)$ and $G(132)$. If there is excessive change in the connectivity, we expect the graph matching performance to suffer. This makes us wonder whether the true match ratio can be used to detect anomalies in a time series of graphs. Graph matching can be performed for the graph instances at consecutive time steps, and significant outliers would be labeled as outliers. The true matching ratio for a fixed number of seeds would be a statistic for anomaly detection. 

\subsubsection{Wikipedia hyperlink subgraph}

Wikipedia is a free online encyclopedia created by volunteers around the world, consisting of millions of article in hundreds of languages (30 million articles in 287 languages, including over 4.3 million on the English Wikipedia site as of November 2013 \cite{wikipedia}). Articles contain text, links to other articles, and multimedia content. We interpret the links as directed edges in a hyperlink graph, where vertices correspond to articles. A collection of articles was obtained from the English Wikipedia site that consisted of the
 directed 2-neighborhood of the document ``Algebraic Geometry''\cite{wikiwebpage}. 
   This  collection of 1382 articles and the correspondence of each article on the French 
Wikipedia site is our real-life dataset. For inference tasks, it is possible to utilize both the textual content of the documents and the hyperlink graph structure. The textual content of the documents is summarized by the bag-of-words model. Dissimilarities between documents  in the same language are computed by the Lin-Pantel discounted mutual information \cite{LinPantel,PantelLin}
 and cosine dissimilarity $k(x_{ik}; x_{jk}) = 1 - (x_{ik} x_{jk})/(\|x_{ik}\|_2\|x_{ik}\|_2)$. 
 The dissimilarities based on the hyperlink graph are the shortest-path distances in the graph, or
 for each pair of vertices $i$ and $j$, the number of vertices one must travel to go from $i$ to $j$. We consider the connected neighborhood of the English  ``Algebraic Geometry'' topic; the induced graph for the French Wikipedia site of the 2-neighborhood from the English Wikipedia site might be a disconnected graph. 
Therefore, the shortest path dissimilarities from the French Wikipedia site are cut off at 6 (maximum shortest-path distance in the English Wikipedia graph).  Further details about this dataset are available in \cite{Zhiliang_disparate}.
 
 Because this graph is relatively large compared with other real-life graphs that we considered, we only tested the modified FAQ algorithm. Note that testing JOFC on this graph is still possible, but we had no reason to believe that another JOFC experiment would provide any new insight.

\begin{figure}
\includegraphics[scale=0.75]{wiki-all-with-unseeded.pdf}
\caption{Graph Matching Experiments on the English and French Wikipedia subgraph for FAQ \label{wiki_graphmatch}}
\end{figure}
      
The results show that there is a strong correlation between the two Wikipedia graphs and that as many as 50 seeds are enough to improve graph matching dramatically. More seeds improve the true matching ratio,  but the improvements are much more modest. With graph matching using no seeds, we obtain a very small number of  true matches. 
%The different values plotted in   \ref{wiki_graphmatch} for the no seed case are just independent repeat
      
\subsubsection{Charitynet graph}

The charitynet dataset consists of timestamped donation relationships between 8052 donors and 756 charities. The donations are divided into two time intervals according to whether they fall before the midpoint of the earliest and latest timestamps. Each group of donations are represented as edges in the bipartite graphs, where vertices correspond to donor or charity entities.

Let $tmid = \frac{(tmax - tmin)}{2}$.
We build two bipartite graphs represented by $B_1$ and $B_2$ for $\left[tmin,tmid\right)$ and $\left(tmid,tmax\right]$, respectively --
each $B^{(t)}$ is $n \times m$, where $n$ is the total number of donors in all of charitynet and $m$ is the total number of charities in all of charitynet.
Therefore, $B_{ij}^{(t)}$ is a 1 if donor $i$ gives to charity $j$ during time interval $t$.

For charities $i$ and $j$,
let $A_{ij}^{(t)}= \sum_{k}{B_{ki}^{(t)}B_{kj}^{(t)}}$, i.e., the number of donors that give funds to both $i$ and $j$  during the time interval $t$.
We consider the two graphs $\Graph_1$ and $\Graph_2$ represented by  $A^{\left[ tmin,tmid \right)}$, $A^{\left[ tmid,tmax\right]}$. These graphs consist of 8052  vertices representing all donors. Because the graphs are too large for matching by any algorithm, we sample pairs of subgraphs from these two graphs, where the pairs consist of the corresponding vertices. Consider the vertices from the largest connected components of $\Graph_1$ and $\Graph_2$, $V_1^*$ and $V_2^*$, respectively. We will slightly abuse the  notation by considering the corresponding vertices to be the same vertex, i.e., $\Graph_1= (V,E_1)$, $\Graph_2= (V,E_2)$. We randomly sample $j$ vertices from  $V_1^* \cap V_2^* \subset V$. For each sampled vertex  pair $v \in V_1^* \cap V_2^*$, we consider $\mcN_1(v,k)$ and $\mcN_2(v,k)$ : the $k$-neighborhood of $v$  in each graph. 
The neighborhood size $k$ is increased in increments of 1, starting from 1 until $\| \mcN_1(v,k) \cap\mcN_2(v',k)\|>n$, where $n$ is the maximum allowable graph size,
which depends on the computation time allotted for the graph matching. We match the  subgraphs of $\Graph_1$ and $\Graph_2$ induced by $\mcN_1(v,k) \cap\mcN_2(v,k)$. 
There is no guarantee that  either of these subgraphs are connected; however, for strongly correlated $\Graph_1$ and $\Graph_2$, they should be mostly connected, i.e., the largest connected component size  is close to the graph size. This connection occurs because the local neighborhood of vertices must be the same for two strongly correlated graphs.

\begin{figure}
\includegraphics[scale=0.4]{charitynet_SGM_JOFCvsFAQ}
\caption{Graph Matching experiments on the two Charitynet graphs for JOFC \label{charitynet_graphmatch}}
\end{figure}
The comparison of the JOFC and FAQ  approaches for CharityNet data\ref{charitynet_graphmatch} show that the two approaches have comparable performances. Both of the approaches have small true matching ratios compared with $1$, which is either  due to the weak correlation between the two graphs, $\Graph_1$ and $\Graph_2$, or due to the related fact that the sampled subgraphs are not mostly connected.

\subsection{One-to-$k$ matching of vertices} 

Consider the case in which the correspondences between vertices of $\Graph_1=(V_1,E_1)$ and $\Graph_2= (V_2,E_2)$ (represented by adjacency matrices, $A$ and $B$, respectively) are not one-to-one. 
To describe the problem in its most general form, we could define group assignment functions $g_1{v_1}: V_1 \rightarrow \mcG={l_1,l_2,\ldots,l_{\upsilon}}$, $g_2{v_2}:V_2 \rightarrow \mcG$, where the inverse images of $g_1{l_i}$, $g_2{l_i}$ are always nonempty. A vertex $v_1 \in  V_1$ in one graph corresponds to a vertex $v_2 \in  V_2$  in another graph, if $g_1(v_1)=g_2(v_2)$. We want to make the simple restriction that $g_2$ is a one-to-one mapping, that is, each vertex in $\Graph_2$ corresponds to at least one vertex in  $\Graph_1$.
For simulations, we consider a very simple case in which the $i^{th}$ vertex in $B$ corresponds to $k_i$ vertices in $A$, where $1\leq k_i \leq k_{max}$ and where $k_{max}$ is the maximum number of corresponding vertices a $B$ vertex can have.  Denote by $g(\cdot)=g_2^{-1}\circ g_1(\cdot) : V_1 \rightarrow V_2$ the correspondence function from vertices in $\Graph_1$ to vertices in $\Graph_2$. Given $r$ vertices in $B$ and the corresponding vertices in $V_1$ for each of the $r$ vertices ($u \in V_1$ such that $g(u)=v_2$), the task is  to find at most $k_max$ closest matches to each vertex of $\Graph_2$. 

The following three information retrieval performance measures are used: Precision, Recall, and F-measure.
$$\textrm{Precision} :=\frac{\textrm{Number of correct matches found}}{\textrm{Number of found matches}}$$
$$\textrm{Recall}    :=\frac{\textrm{Number of correct matches found}}{\textrm{Number of true matches}}$$

$$\textrm{F-measure}  :=\frac{2 \times \textrm{Precision} \times \textrm{Recall}}{\textrm{Precision} + \textrm{Recall}}$$

For each vertex $i$ of $\Graph_2$, the number of true matches is $k_i$. The three performance measures are calculated for each vertex of $\Graph_2$, and then, the three averages over all vertices $B$ constitute the performance measures computed for the matching.

\begin{figure}
\includegraphics[scale=0.65]{Total_precision_JOFC_1_to_k_match_paper.pdf}
\caption{Graph Matching experiments on simulated graphs for JOFC \label{1_k_graphmatch_sim}}
\end{figure}

The results provide evidence that JOFC is a suitable method for solving this variation of  the graph matching problem. While both the JOFC approach and modified FAQ were acceptable algorithms for the approximate graph matching (AGM) problem with one-to-one corres\-pondence between vertices, with comparable matching performances, modified FAQ  cannot directly solve  the one-to-$k$ correspondence variation of the GM problem. In contrast, JOFC is quite adequate for solving AGM with one-to-$k$ correspondence. We only need to use a matching algorithm that allows for multiple assignments for the vertices of one of the graphs. We use the full matching algorithm implemented in the R package \cite{optmatch}, which finds  ``a matching between units that minimizes the average within-group distances, given a matrix describing the distances between two groups''\cite{optmatch_manual}. That is, the \emph{full} matching algorithm finds an assignment for all of the vertices in both graphs. Because the assignment problem is independent of the embedding, other matching algorithms can be used with the same embedding, if one is concerned about efficiency or other aspects of the matching algorithm.
